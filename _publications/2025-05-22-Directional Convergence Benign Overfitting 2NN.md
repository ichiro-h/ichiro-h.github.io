---
title: "Directional Convergence, Benign Overfitting of Gradient Descent in leaky ReLU two-layer Neural Networks"
collection: publications
permalink: /publication/2025-05-22-Directional-Convergence-Benign-Overfitting-2NN
excerpt: 'In this paper, we prove directional convergence of network parameters of fixed width leaky ReLU two-layer neural networks optimized by gradient descent with exponential loss, which was previously only known for gradient flow. By a careful analysis of the convergent direction, we establish sufficient conditions of benign overfitting and discover a new phase transition in the test error bound. All of these results hold beyond the nearly orthogonal data setting which was studied in prior works. As an application, we demonstrate that benign overfitting occurs with high probability in sub-Gaussian mixture models.'
date: '2025-05-22'
venue: 'Accepted to ICLR2026'
slidesurl: 
paperurl: 'https://arxiv.org/abs/2505.16204'
citation: 
---

In this paper, we prove directional convergence of network parameters of fixed width leaky ReLU two-layer neural networks optimized by gradient descent with exponential loss, which was previously only known for gradient flow. By a careful analysis of the convergent direction, we establish sufficient conditions of benign overfitting and discover a new phase transition in the test error bound. All of these results hold beyond the nearly orthogonal data setting which was studied in prior works. As an application, we demonstrate that benign overfitting occurs with high probability in sub-Gaussian mixture models.